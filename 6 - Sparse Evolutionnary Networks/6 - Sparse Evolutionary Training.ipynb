{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow numpy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction to Evolutionary Sparse Networks**\n",
    "\n",
    "This Python code implements a sparse evolutionary neural network model, which is a type of neural network that evolves its sparse connectivity during training. The model is designed to maintain a certain level of sparsity, which means that a portion of the model's weights are set to zero. This sparsity is achieved through a process of pruning and growing weights, which is inspired by the concept of synaptic pruning in biological neural networks.\n",
    "\n",
    "**How the Pruning and Growing Process Works**\n",
    "\n",
    "The pruning and growing process is inspired by the concept of synaptic pruning in biological neural networks. The idea is to remove unnecessary connections (pruning) and create new ones (growing) to adapt to the data distribution. This process is repeated after each epoch, allowing the model to evolve its sparse connectivity during training.\n",
    "\n",
    "By maintaining a certain level of sparsity, the model can reduce its computational complexity and memory usage, making it more efficient and scalable. The pruning and growing process also helps to prevent overfitting by removing redundant connections and promoting the growth of new, useful connections.\n",
    "\n",
    "**Code Explanation**\n",
    "\n",
    "The code defines a `SparseEvolutionaryModel` class, which inherits from TensorFlow's `tf.keras.Model`. This class has three main methods: `__init__`, `call`, and `prune_and_grow_weights`.\n",
    "\n",
    "### `__init__` Method\n",
    "\n",
    "The `__init__` method initializes the model with the following parameters:\n",
    "\n",
    "- `input_dim`: The number of input features.\n",
    "- `output_dim`: The number of output features.\n",
    "- `sparsity`: The desired level of sparsity in the model, which is the proportion of weights that should be set to zero.\n",
    "\n",
    "The method creates a dense layer with the specified input and output dimensions and initializes its weights to zero to simulate sparsity.\n",
    "\n",
    "### `call` Method\n",
    "\n",
    "The `call` method defines the forward pass through the model. It simply applies the dense layer to the input.\n",
    "\n",
    "### `prune_and_grow_weights` Method\n",
    "\n",
    "The `prune_and_grow_weights` method is responsible for pruning and growing the model's weights. Here's how it works:\n",
    "\n",
    "1. **Pruning**: The method identifies the weights with the smallest absolute values and sets them to zero until the desired level of sparsity is reached.\n",
    "2. **Growing**: The method randomly selects a set of zero weights and sets them to small random values, effectively growing new connections in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0775656700134277\n",
      "Epoch 2, Loss: 1.1435668468475342\n",
      "Epoch 3, Loss: 1.1436902284622192\n",
      "Epoch 4, Loss: 1.1453701257705688\n",
      "Epoch 5, Loss: 1.1585590839385986\n",
      "Epoch 6, Loss: 1.160218596458435\n",
      "Epoch 7, Loss: 1.1713939905166626\n",
      "Epoch 8, Loss: 1.1695351600646973\n",
      "Epoch 9, Loss: 1.1695655584335327\n",
      "Epoch 10, Loss: 1.1803079843521118\n"
     ]
    }
   ],
   "source": [
    "class SparseEvolutionaryModel(tf.keras.Model):\n",
    "    def __init__(self, input_dim, output_dim, sparsity=0.1):\n",
    "        super(SparseEvolutionaryModel, self).__init__()\n",
    "        self.sparsity = sparsity\n",
    "        self.dense = tf.keras.layers.Dense(output_dim, use_bias=False)\n",
    "        # Manually initialize weights to zero to simulate sparsity\n",
    "        self.dense.build((None, input_dim))  # Initialize weights\n",
    "        weights = np.zeros(self.dense.kernel.shape)\n",
    "        self.dense.kernel.assign(weights)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "    def prune_and_grow_weights(self):\n",
    "        # Convert weights to numpy for manipulation\n",
    "        weights = self.dense.kernel.numpy()\n",
    "        nonzero_indices = weights.nonzero()\n",
    "        num_nonzero = len(nonzero_indices[0])\n",
    "        num_to_prune = int(num_nonzero * self.sparsity)\n",
    "\n",
    "        # Prune\n",
    "        if num_nonzero > 0:\n",
    "            abs_weights = np.abs(weights)\n",
    "            flat_indices = np.argpartition(abs_weights.flatten(), num_to_prune)[:num_to_prune]\n",
    "            weights.flat[flat_indices] = 0\n",
    "\n",
    "        # Grow\n",
    "        zero_indices = np.where(weights == 0)\n",
    "        num_possible_grows = len(zero_indices[0])\n",
    "        if num_possible_grows > 0:\n",
    "            indices_to_grow = np.random.choice(np.arange(num_possible_grows), size=num_to_prune, replace=False)\n",
    "            weights[zero_indices[0][indices_to_grow], zero_indices[1][indices_to_grow]] = np.random.randn(num_to_prune) * 0.1\n",
    "\n",
    "        # Assign modified weights back to the layer\n",
    "        self.dense.kernel.assign(weights)\n",
    "\n",
    "# Dummy data\n",
    "input_dim = 10\n",
    "output_dim = 1\n",
    "X = np.random.randn(1000, input_dim).astype(np.float32)\n",
    "y = np.random.randn(1000, output_dim).astype(np.float32)\n",
    "\n",
    "# Model and optimizer\n",
    "model = SparseEvolutionaryModel(input_dim, output_dim, sparsity=0.1)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(X)\n",
    "        loss = tf.reduce_mean((predictions - y) ** 2)\n",
    "    \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    # After each epoch, prune and grow weights\n",
    "    model.prune_and_grow_weights()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.numpy()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
